-------------------LR: 0.001, hidden layer dim = 8, 100 epochs---------------------------------------

Run 1 after transformation of data:

Total MSE Loss by epoch 100: 70.22.

Top 10 largest prediction errors:
S22by7-15-1.5: Error = 3.8947 hartree
S22-5: Error = 2.8275 hartree
S22by7-5-0.7: Error = 2.7615 hartree
S22by7-13-0.8: Error = 2.5122 hartree
S22by7-22-2.0: Error = 2.1811 hartree
S22by7-22-1.5: Error = 2.0839 hartree
S22by7-6-1.2: Error = 2.0411 hartree
S22by7-22-1.2: Error = 2.0380 hartree
S22-21: Error = 2.0149 hartree
S22-22: Error = 2.0068 hartree

Run 2 after transformation of data:

Total MSE Loss by epoch 100: 11.822115.

Top 10 largest prediction errors:
S22by7-15-1.5: Error = 3.1195 hartree
S22by7-5-0.7: Error = 2.3228 hartree
S22-5: Error = 2.2768 hartree
S22by7-13-0.8: Error = 2.2481 hartree
S22by7-22-2.0: Error = 1.8086 hartree
S22by7-22-1.5: Error = 1.6299 hartree
S22by7-6-1.2: Error = 1.6056 hartree
S22by7-22-0.7: Error = 1.5990 hartree
S22-6: Error = 1.5691 hartree
S22by7-6-1.0: Error = 1.5681 hartree

Run 3 after transformation of data:

Total MSE Loss by epoch 100: 50.779744.

Top 10 largest prediction errors:
S22by7-15-1.5: Error = 3.4310 hartree
S22-5: Error = 2.3799 hartree
S22by7-5-0.7: Error = 2.2406 hartree
S22by7-22-2.0: Error = 1.9337 hartree
S22by7-22-1.5: Error = 1.8145 hartree
S22by7-22-1.2: Error = 1.7200 hartree
S22by7-6-1.2: Error = 1.7171 hartree
S22by7-6-1.0: Error = 1.6350 hartree
S22-6: Error = 1.6340 hartree
S22by7-22-1.0: Error = 1.6283 hartree

Run 4 after tranformation of data:

Total MSE Loss by epoch 100: Approx 133.929901.

Top 10 largest prediction errors:
S22by7-15-1.5: Error = 5.6081 hartree
S22-5: Error = 3.8973 hartree
S22by7-5-0.7: Error = 3.6585 hartree
S22by7-22-2.0: Error = 3.1999 hartree
S22by7-22-1.5: Error = 2.9493 hartree
S22by7-6-1.2: Error = 2.7886 hartree
S22by7-22-1.2: Error = 2.7669 hartree
S22-6: Error = 2.6429 hartree
S22by7-6-1.0: Error = 2.6420 hartree
S22-22: Error = 2.6162 hartree


Run 5:

Epoch 100: Total MSE Loss = 140.647890

Top 10 largest prediction errors:
S22by7-15-1.5: Error = 5.9470 hartree
S22-5: Error = 3.9798 hartree
S22by7-5-0.7: Error = 3.5692 hartree
S22by7-22-2.0: Error = 3.5081 hartree
S22by7-22-1.5: Error = 3.0812 hartree
S22by7-6-1.2: Error = 2.7976 hartree
S22by7-22-1.2: Error = 2.7609 hartree
S22by7-6-1.0: Error = 2.5464 hartree
S22-6: Error = 2.5454 hartree
S22by7-22-1.0: Error = 2.5085 hartree


-------------------LR: 0.001, hidden layer dim = 16, 100 epochs---------------------------------------

Run 1:

Epoch 100: Total MSE Loss = 171.599010

Top 10 largest prediction errors:
S22by7-15-1.5: Error = 6.1926 hartree
S22-5: Error = 4.4175 hartree
S22by7-5-0.7: Error = 4.2515 hartree
S22by7-13-0.8: Error = 3.5386 hartree
S22by7-22-2.0: Error = 3.4435 hartree
S22by7-22-1.5: Error = 3.2943 hartree
S22by7-6-1.2: Error = 3.2038 hartree
S22by7-22-1.2: Error = 3.1933 hartree
S22-21: Error = 3.1237 hartree
S22-6: Error = 3.1168 hartree


Run 2:

Epoch 100: Total MSE Loss = 116.887120

Top 10 largest prediction errors:
S22by7-15-1.5: Error = 5.8092 hartree
S22by7-5-0.7: Error = 4.4555 hartree
S22-5: Error = 4.2676 hartree
S22by7-13-0.8: Error = 3.8089 hartree
S22by7-22-2.0: Error = 3.2314 hartree
S22by7-22-1.5: Error = 3.0878 hartree
S22by7-6-0.9: Error = 3.0823 hartree
S22by7-6-1.2: Error = 3.0634 hartree
S22by7-6-1.0: Error = 3.0573 hartree
S22-6: Error = 3.0564 hartree

Run 3:

Epoch 100: Total MSE Loss = 21.161371

Top 10 largest prediction errors:
S22by7-15-1.5: Error = 2.5958 hartree
S22-5: Error = 1.8606 hartree
S22by7-5-0.7: Error = 1.7478 hartree
S22by7-22-2.0: Error = 1.5599 hartree
S22by7-13-0.8: Error = 1.4691 hartree
S22by7-22-1.5: Error = 1.3776 hartree
S22by7-6-1.2: Error = 1.3018 hartree
S22by7-22-1.2: Error = 1.2759 hartree
S22-6: Error = 1.2382 hartree
S22by7-6-1.0: Error = 1.2372 hartree

-------------------LR: 0.0001 (smaller than above), hidden layer dim = 8, 100 epochs------------------

Run 1:

Epoch 100: Total MSE Loss = 11.068267

Top 10 largest prediction errors:
S22by7-13-0.8: Error = 1.9263 hartree
S22by7-15-1.5: Error = 1.2111 hartree
S22by7-22-2.0: Error = 0.9445 hartree
S22by7-22-1.5: Error = 0.5341 hartree
S22-12: Error = 0.5078 hartree
S22by7-3-0.7: Error = 0.5043 hartree
S22-5: Error = 0.4999 hartree
S22by7-4-0.7: Error = 0.4944 hartree
S22by7-22-0.7: Error = 0.4832 hartree
S22-11: Error = 0.4625 hartree

Run 2:
Epoch 100: Total MSE Loss = 316.328292
Top 10 largest prediction errors:
S22by7-13-0.8: Error = 8.5651 hartree
S22by7-15-1.5: Error = 8.4771 hartree
S22by7-22-2.0: Error = 6.0761 hartree
S22-5: Error = 4.1816 hartree
S22by7-22-1.5: Error = 3.9553 hartree
S22by7-3-0.7: Error = 2.4951 hartree
S22by7-4-0.7: Error = 2.4801 hartree
S22by7-6-1.2: Error = 2.4618 hartree
S22by7-22-1.2: Error = 2.2937 hartree
S22by7-9-0.7: Error = 2.1864 hartree

Run 3:

Epoch 100: Total MSE Loss = 2.891278

Top 10 largest prediction errors:
S22by7-13-0.8: Error = 0.7627 hartree
S22by7-15-1.5: Error = 0.6973 hartree
S22by7-22-2.0: Error = 0.4998 hartree
S22-5: Error = 0.3388 hartree
S22by7-22-1.5: Error = 0.3251 hartree
S22by7-4-0.7: Error = 0.2940 hartree
S22by7-3-0.7: Error = 0.2886 hartree
S22by7-3-0.8: Error = 0.2195 hartree
S22by7-4-0.8: Error = 0.2078 hartree
S22by7-9-0.7: Error = 0.2061 hartree

Run 4:

Epoch 100: Total MSE Loss = 2.252895

Top 10 largest prediction errors:
S22by7-15-1.5: Error = 0.6960 hartree
S22-5: Error = 0.4997 hartree
S22by7-5-0.7: Error = 0.4618 hartree
S22by7-13-0.8: Error = 0.3990 hartree
S22by7-22-2.0: Error = 0.3820 hartree
S22by7-22-1.5: Error = 0.3719 hartree
S22-21: Error = 0.3667 hartree
S22by7-6-1.2: Error = 0.3653 hartree
S22by7-22-1.2: Error = 0.3652 hartree
S22-22: Error = 0.3576 hartree

Run 5:

Epoch 100: Total MSE Loss = 4.118754

Top 10 largest prediction errors:
S22by7-13-0.8: Error = 1.1703 hartree
S22by7-15-1.5: Error = 0.7706 hartree
S22by7-22-2.0: Error = 0.5979 hartree
S22by7-22-1.5: Error = 0.3412 hartree
S22-5: Error = 0.3258 hartree
S22-12: Error = 0.3104 hartree
S22by7-3-0.7: Error = 0.2901 hartree
S22by7-22-0.7: Error = 0.2842 hartree
S22-11: Error = 0.2814 hartree
S22by7-4-0.7: Error = 0.2813 hartree

-------------------LR: 0.0001 , hidden layer dim = 16, 100 epochs--------------------------------------

Run 1:

Epoch 100: Total MSE Loss = 15.858676

Top 10 largest prediction errors:
S22by7-13-0.8: Error = 2.3432 hartree
S22by7-15-1.5: Error = 1.3775 hartree
S22by7-22-2.0: Error = 1.1191 hartree
S22-12: Error = 0.6906 hartree
S22-11: Error = 0.6334 hartree
S22by7-22-0.7: Error = 0.6144 hartree
S22by7-22-1.5: Error = 0.5893 hartree
S22-5: Error = 0.5608 hartree
S22by7-4-0.7: Error = 0.5404 hartree
S22by7-3-0.7: Error = 0.5258 hartree

Run 2:

Epoch 100: Total MSE Loss = 49.864769

Top 10 largest prediction errors:
S22by7-13-0.8: Error = 4.0982 hartree
S22by7-15-1.5: Error = 2.4863 hartree
S22by7-22-2.0: Error = 1.9465 hartree
S22by7-3-0.7: Error = 1.1096 hartree
S22by7-4-0.7: Error = 1.0980 hartree
S22by7-22-1.5: Error = 1.0932 hartree
S22-12: Error = 1.0743 hartree
S22by7-22-0.7: Error = 1.0513 hartree
S22-5: Error = 1.0068 hartree
S22-11: Error = 0.9820 hartree

Run 3:

Epoch 100: Total MSE Loss = 17.333630

Top 10 largest prediction errors:
S22by7-13-0.8: Error = 2.4190 hartree
S22by7-15-1.5: Error = 1.4307 hartree
S22by7-22-2.0: Error = 1.1173 hartree
S22by7-4-0.7: Error = 0.6632 hartree
S22by7-3-0.7: Error = 0.6518 hartree
S22by7-22-1.5: Error = 0.6299 hartree
S22by7-22-0.7: Error = 0.6191 hartree
S22-12: Error = 0.6175 hartree
S22-5: Error = 0.5750 hartree
S22-11: Error = 0.5676 hartree

Run 4:

Epoch 100: Total MSE Loss = 15.533665

Top 10 largest prediction errors:
S22by7-13-0.8: Error = 2.1951 hartree
S22by7-15-1.5: Error = 1.3901 hartree
S22by7-22-2.0: Error = 1.0682 hartree
S22by7-4-0.7: Error = 0.7104 hartree
S22by7-3-0.7: Error = 0.7059 hartree
S22by7-22-1.5: Error = 0.6198 hartree
S22by7-3-0.8: Error = 0.5860 hartree
S22by7-22-0.7: Error = 0.5657 hartree
S22-5: Error = 0.5634 hartree
S22by7-4-0.8: Error = 0.5620 hartree

-------------------LR: 0.001 , hidden layer dim = 4, 100 epochs---------------------------
Run 1:

Epoch 100: Total MSE Loss = 38.006867

Top 10 largest prediction errors:
S22by7-15-1.5: Error = 3.0972 hartree
S22-5: Error = 2.0230 hartree
S22by7-22-2.0: Error = 1.8413 hartree
S22by7-5-0.7: Error = 1.6971 hartree
S22by7-22-1.5: Error = 1.5943 hartree
S22by7-6-1.2: Error = 1.4188 hartree
S22by7-22-1.2: Error = 1.4015 hartree
S22-6: Error = 1.2560 hartree
S22by7-6-1.0: Error = 1.2550 hartree
S22-22: Error = 1.2438 hartree

Run 2:
Epoch 100: Total MSE Loss = 85.692794

Top 10 largest prediction errors:
S22by7-15-1.5: Error = 4.6487 hartree
S22-5: Error = 3.1415 hartree
S22by7-5-0.7: Error = 2.8728 hartree
S22by7-22-2.0: Error = 2.7217 hartree
S22by7-22-1.5: Error = 2.4170 hartree
S22by7-6-1.2: Error = 2.2168 hartree
S22by7-22-1.2: Error = 2.1899 hartree
S22by7-6-1.0: Error = 2.0410 hartree
S22-6: Error = 2.0400 hartree
S22by7-22-1.0: Error = 2.0106 hartree


-------------------LR: 0.0001 , hidden layer dim = 16, 200 epochs(prev. 100)---------------------------

Epoch 200: Total MSE Loss = 0.385678

Top 10 largest prediction errors:
S22by7-13-0.8: Error = 0.4317 hartree
S22-11: Error = 0.2187 hartree
S22-12: Error = 0.2004 hartree
S22-21: Error = 0.1210 hartree
S22by7-22-0.8: Error = 0.1159 hartree
S22by7-22-0.7: Error = 0.1121 hartree
S22by7-22-0.9: Error = 0.1020 hartree
S22by7-9-0.7: Error = 0.0994 hartree
S22by7-22-1.0: Error = 0.0990 hartree
S22-22: Error = 0.0981 hartree

Run 2:
Epoch 200: Total MSE Loss = 1.049732

Top 10 largest prediction errors:
S22by7-15-1.5: Error = 0.4936 hartree
S22by7-22-2.0: Error = 0.4647 hartree
S22by7-13-0.8: Error = 0.4070 hartree
S22-5: Error = 0.3921 hartree
S22by7-5-0.7: Error = 0.3842 hartree
S22by7-22-1.5: Error = 0.2953 hartree
S22by7-22-0.9: Error = 0.2703 hartree
S22-22: Error = 0.2683 hartree
S22by7-22-1.0: Error = 0.2674 hartree
S22by7-22-1.2: Error = 0.2587 hartree

Run 3:

Epoch 200: Total MSE Loss = 0.197562

Top 10 largest prediction errors:
S22by7-15-1.5: Error = 0.2521 hartree
S22by7-5-0.7: Error = 0.2250 hartree
S22-5: Error = 0.1712 hartree
S22by7-22-2.0: Error = 0.1485 hartree
S22by7-22-1.5: Error = 0.1309 hartree
S22by7-6-0.9: Error = 0.1244 hartree
S22by7-6-1.2: Error = 0.1203 hartree
S22by7-22-1.2: Error = 0.1184 hartree
S22by7-6-1.0: Error = 0.1163 hartree
S22-6: Error = 0.1153 hartree



Worst performing file is S22by7-15-1.5 on all modalities. Features of this file:

600 pairs ---> Higher than average (highest?)
Lowest Sij: 1.3e-7
Highest Sij: Around 1.5e-3
SAPT: -0.0024801508060000002 (not out of the norm)
Undamped: -0.0022067133000000035 (doesn't seem out of the norm)

S22by7-5-0.7: Error = 0.2250 hartree (441 pairs)
S22by7-22-2.0 (325 pairs)
S22by7-13-0.8(441 pairs)
S22-5: 441 pairs

----------------------------------------------------------All tests above are on 78 samples-----------------------------------------------------------

-------------------LR: 0.001 , hidden layer dim = 8, 100 epochs, 110 samples---------------------------
Run1:

Epoch 100: Total MSE Loss = 82.040959
The average loss per system by the last epoch was: 1.0255765035995976

Top 10 largest prediction errors:
S22by7-15-1.5: Error = 6.5711 hartree
ACHC-AC-4.0_____: Error = 5.5687 hartree
ACHC-AC-3.8_____: Error = 5.5116 hartree
ACHC-AC-3.4_2.0____: Error = 5.4734 hartree
ACHC-AC-3.6____4_: Error = 5.4582 hartree
ACHC-AC-3.6_____4: Error = 5.4547 hartree
ACHC-AC-3.6_____n4: Error = 5.4541 hartree
ACHC-AC-3.6_____: Error = 5.4539 hartree
ACHC-AC-3.6_____n8: Error = 5.4532 hartree
ACHC-AC-3.6_____n12: Error = 5.4494 hartree

-------------------LR: 0.0001 , hidden layer dim = 8, 200 epochs, 110 samples---------------------------
Run 1:

Epoch 200: Total MSE Loss = 0.356071
The average loss per system by the last epoch was: 0.06756491006810855

Top 10 largest prediction errors:
S22by7-15-1.5: Error = 0.2649 hartree
ACHC-AC-4.0_____: Error = 0.1873 hartree
ACHC-AC-3.8_____: Error = 0.1723 hartree
S22-5: Error = 0.1678 hartree
S22by7-22-2.0: Error = 0.1596 hartree
ACHC-AC-3.4_2.0____: Error = 0.1585 hartree
ACHC-AC-3.6____4_: Error = 0.1577 hartree
ACHC-AC-3.6_____4: Error = 0.1565 hartree
ACHC-AC-3.6_____: Error = 0.1564 hartree
ACHC-AC-3.6_____n4: Error = 0.1562 hartree

Run 2:

Epoch 200: Total MSE Loss = 15.820090
The average loss per system by the last epoch was: 0.4503572663640763

Top 10 largest prediction errors:
S22by7-13-0.8: Error = 2.1224 hartree
S22by7-15-1.5: Error = 1.3374 hartree
S22by7-22-2.0: Error = 1.0300 hartree
ACHC-AC-3.2_____: Error = 0.8898 hartree
S22by7-4-0.7: Error = 0.6185 hartree
S22by7-3-0.7: Error = 0.6073 hartree
ACHC-AC-3.4___90__: Error = 0.5955 hartree
S22by7-22-1.5: Error = 0.5947 hartree
ACHC-AC-3.4__0.4___: Error = 0.5671 hartree
S22-5: Error = 0.5539 hartree

Run 3:

Epoch 200: Total MSE Loss = 0.614016
The average loss per system by the last epoch was: 0.08872430529469905

Top 10 largest prediction errors:
ACHC-AC-3.4_0.8____: Error = 0.2616 hartree
ACHC-AC-3.4_1.2____: Error = 0.2501 hartree
ACHC-AC-3.4__0.4___: Error = 0.2499 hartree
ACHC-AC-3.4_0.4____: Error = 0.2437 hartree
ACHC-AC-3.4__n0.8___: Error = 0.2415 hartree
ACHC-AC-3.4___60__: Error = 0.2411 hartree
ACHC-AC-3.6_____4: Error = 0.2409 hartree
ACHC-AC-3.4__0.8___: Error = 0.2397 hartree
ACHC-AC-3.6_____: Error = 0.2396 hartree
ACHC-AC-3.4___90__: Error = 0.2373 hartree

-------------------LR: 0.0001 , hidden layer dim = 8, 300 epochs, 110 samples---------------------------

Epoch 300: Total MSE Loss = 0.659486
The average loss per system by the last epoch was: 0.09195076362048502

Top 10 largest prediction errors:
S22by7-15-1.5: Error = 0.1408 hartree
S22-5: Error = 0.0954 hartree
S22by7-5-0.7: Error = 0.0939 hartree
S22by7-22-2.0: Error = 0.0902 hartree
ACHC-AC-4.0_____: Error = 0.0842 hartree
ACHC-AC-3.8_____: Error = 0.0723 hartree
S22by7-22-1.5: Error = 0.0703 hartree
ACHC-AC-3.4_2.0____: Error = 0.0666 hartree
S22by7-6-0.9: Error = 0.0625 hartree
ACHC-AC-3.6____4_: Error = 0.0616 hartree



